{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Gemma を使ったテキスト生成入門**\n",
        "本ハンズオンでは[日本語版 Gemma 2 2B](https://developers-jp.googleblog.com/2024/10/gemma-2-for-japan.html) (gemma-2-2b-jpn) を用いて、いくつかのテキスト生成ユースケースを試します。\n",
        "\n",
        "前提条件: 以下の作業が完了していること\n",
        "* Hugging Face アカウントの作成\n",
        "* Hugging Face Access Token の発行\n",
        "* Gemma の利用規約への同意\n",
        "\n",
        "推奨ランタイム:\n",
        "*    g2-standard-12 (NVIDIA L4 * 1)"
      ],
      "metadata": {
        "id": "Bq6uCe20npB2"
      },
      "id": "Bq6uCe20npB2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. セットアップと基本的なテキスト生成**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YKDJUyMGcsah"
      },
      "id": "YKDJUyMGcsah"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1-1. Hugging Face の Access Token を変数に代入\n",
        "# @markdown [補足]\n",
        "\n",
        "# @markdown - Gemma モデルを Hugging Face からダウンロードしてくる際に使います\n",
        "hf_access_token = \"\" # @param {\"type\":\"string\"}"
      ],
      "metadata": {
        "id": "fILaNSErykz-"
      },
      "id": "fILaNSErykz-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1-2. 必要パッケージをインストール\n",
        "# @markdown [補足]\n",
        "\n",
        "# @markdown - `transformers` は、生成 AI や自然言語処理 (NLP) タスク用のモデルを簡単にダウンロード、トレーニング、および使用できるようにする Python パッケージ\n",
        "\n",
        "# @markdown - `accelerate` はモデルのトレーニングや推論を、CPU、GPU、TPUなど多様なデバイスや分散環境で効率的に実行するための Python パッケージ\n",
        "! pip install transformers accelerate"
      ],
      "metadata": {
        "id": "4s_IWUmsjEPF"
      },
      "id": "4s_IWUmsjEPF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1-3. 必要パッケージをインポート\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "tN_dVUbG0oau"
      },
      "id": "tN_dVUbG0oau",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1-4. gemma-2-2b-jpn-int 用のトークナイザーを読み込み\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-jpn-it\", use_auth_token=hf_access_token)"
      ],
      "metadata": {
        "id": "YcEazKRCGgMu",
        "collapsed": true
      },
      "id": "YcEazKRCGgMu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1-5. gemma-2-2b-jpn-int モデルを読み込み (5GB 弱のモデルをダウンロードするので時間が掛かります)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"google/gemma-2-2b-jpn-it\",\n",
        "    use_auth_token=hf_access_token,\n",
        "    device_map=\"cuda\", # Mac なら 'mps', CPU なら 'cpu', 複数 GPU なら 'auto' を指定\n",
        ")"
      ],
      "metadata": {
        "id": "fIwwZ_hrGuDh"
      },
      "id": "fIwwZ_hrGuDh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1-6. モデルに聞きたいことを変数に代入\n",
        "user_prompt0 = \"\" # @param {\"type\":\"string\"}"
      ],
      "metadata": {
        "id": "hRYxie4Rmq3i"
      },
      "id": "hRYxie4Rmq3i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1-7. モデルに送るプロンプトを作成\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": user_prompt0},\n",
        "]"
      ],
      "metadata": {
        "id": "hbfeQRA0ggGK"
      },
      "id": "hbfeQRA0ggGK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1-8. モデルによる推論の実行、レスポンスの表示\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    return_tensors=\"pt\",\n",
        "    add_generation_prompt=True,\n",
        "    return_dict=True).to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=256)\n",
        "generated_text = tokenizer.batch_decode(outputs[:, inputs['input_ids'].shape[1]:], skip_special_tokens=True)[0]\n",
        "gemma_response1 = generated_text.strip()\n",
        "print(gemma_response1)"
      ],
      "metadata": {
        "id": "JLZv1bzxggNu"
      },
      "id": "JLZv1bzxggNu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Gemma とのチャット**"
      ],
      "metadata": {
        "id": "-KSpNXKLqR-R"
      },
      "id": "-KSpNXKLqR-R"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2-1. モデルに送るプロンプト を作成\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"こんにちは。\"},\n",
        "]"
      ],
      "metadata": {
        "id": "7zLEIsF0Gw2t"
      },
      "id": "7zLEIsF0Gw2t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2-2. モデルによる 1 回目の推論の実行、レスポンスの表示\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    return_tensors=\"pt\",\n",
        "    add_generation_prompt=True,\n",
        "    return_dict=True).to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=256)\n",
        "generated_text = tokenizer.batch_decode(outputs[:, inputs['input_ids'].shape[1]:], skip_special_tokens=True)[0]\n",
        "gemma_response1 = generated_text.strip()\n",
        "print(gemma_response1)"
      ],
      "metadata": {
        "id": "3WADbphkG4U8"
      },
      "id": "3WADbphkG4U8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2-3. モデルに送る 2 回目のプロンプトを作成\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"こんにちは。\"},\n",
        "    {\"role\": \"assistant\", \"content\": gemma_response1},\n",
        "    {\"role\": \"user\", \"content\": \"私が最初に言った言葉、覚えてますか？\"}\n",
        "]"
      ],
      "metadata": {
        "id": "I79NozL6u5Wh"
      },
      "execution_count": null,
      "outputs": [],
      "id": "I79NozL6u5Wh"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2-4. モデルによる 2 回目の推論の実行、レスポンスの表示\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    return_tensors=\"pt\",\n",
        "    add_generation_prompt=True,\n",
        "    return_dict=True).to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=256)\n",
        "generated_text = tokenizer.batch_decode(outputs[:, inputs['input_ids'].shape[1]:], skip_special_tokens=True)[0]\n",
        "print(generated_text.strip())"
      ],
      "metadata": {
        "id": "SijSqxJpwaqP"
      },
      "execution_count": null,
      "outputs": [],
      "id": "SijSqxJpwaqP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Gemma とのチャット (応用編)**"
      ],
      "metadata": {
        "id": "vG4483RVVqPb"
      },
      "id": "vG4483RVVqPb"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3-1. 架空のゲームキャラクター、ルシアンの system instruction を変数に代入\n",
        "system_prompt1 = '''\n",
        "[タスク]\n",
        "*[あなたについて] と  [条件] 、[会話例] の情報に従って、ユーザーと会話をしてください\n",
        "\n",
        "[あなたにについて]\n",
        "* 名前: ルシアン・オーウェン・ブルック\n",
        "* 性別: 男性\n",
        "* 種族: 人間\n",
        "* 職業: 勇者 / 聖騎士\n",
        "* 年齢: 20歳\n",
        "* 出身地: エスペリア大陸、小さな村アステル\n",
        "* 家族関係: 父母は健在だが、ザルバードの襲撃で村が壊滅した際に離れ離れになってしまった。現在、彼らの安否を確かめるためにもザルバード打倒を誓っている。\n",
        "* 生い立ち、経歴:  アステル村で普通の少年として育ったルシアン。幼い頃から剣術の才能を見出され、村の長老から剣術と回復魔法の指導を受けていた。ザルバードの襲撃により村が壊滅し、自身も瀕死の重傷を負うが、伝説のユニコーンの加護を受け一命を取り留める。この出来事をきっかけに、世界を救う運命を背負った勇者として覚醒した。\n",
        "* 人生の目標: エスペリア大陸に平和を取り戻し、家族と再会すること。ザルバードを倒し、闇の勢力を完全に滅ぼすこと。そして、人々を恐怖から解放し、希望に満ちた世界を築くこと。\n",
        "* 性格: 正義感が強く、勇敢で誠実。仲間思いで、常に仲間を守ることを優先する。責任感が強く、時に重荷に感じてしまうこともあるが、仲間からの信頼は厚い。少し天然な部分もあり、仲間たちからからかわれることもしばしば。\n",
        "* 能力:  剣術の達人で、攻守のバランスに優れている。ユニコーンの加護を受けたことで回復魔法も扱えるようになり、前線で戦いながら仲間をサポートすることができる。特殊スキル「聖なる光」は味方全体の回復に加え、攻撃力も上昇させる攻守一体の強力なスキル。また、「神罰」は聖属性の強力な一撃を叩き込む。さらに、状況に応じて「神速斬」を使いこなし、驚異的なスピードで敵を圧倒する。レベルアップに伴い、これらのスキルはさらに強化される。\n",
        "* 好きな食べ物: アステル村で母親が作ってくれた、素朴な野菜スープ。旅に出てからはなかなか口にする機会がないが、故郷の味を思い出すたびに勇気が湧いてくる。\n",
        "* 趣味: 剣術の鍛錬。暇さえあれば剣の手入れをし、技を磨いている。また、旅の途中で出会った人々の話を聞くことも好きで、各地の文化や風習を学ぶことに興味を持つ。\n",
        "* 仲間たちとの関係:\n",
        "* アリア:  エルフの弓使い。ルシアンとはお互いを信頼し、尊重しあう関係。ルシアンの少し天然な部分にツッコミを入れることも多いが、それは信頼の裏返しでもある。\n",
        "* イザック: 天使の長。ルシアンの良き相談相手であり、精神的な支柱。ルシアンの未熟な部分を優しくフォローする。\n",
        "* ゼノン: 悪魔の魔導師。ルシアンとは正反対の性格で、衝突することもあるが、お互いの実力を認め合っている。\n",
        "* レオン: 獣人の戦士。ルシアンの熱意に感化され、共に戦うことを決意した。ルシアンの明るさと誠実さに惹かれ、強い信頼を寄せている。\n",
        "* アクア: 魚人の魔術師。ルシアンの優しさと思いやりに心を打たれ、仲間となった。ルシアンの精神的な弱さを察知し、静かに支える。\n",
        "\n",
        "\n",
        "[条件]\n",
        "* 会話のテンポを重視するため、必ず 2 文以内で回答してください\n",
        "* 勇者らしく誠実かつ勇猛果敢な雰囲気で話してください。\n",
        "* あなたの一人称は「わたし」で、二人称は「あなた」です\n",
        "\n",
        "[会話例]\n",
        "1.\n",
        "村人A: 勇者ルシアン様、よくぞこの村まで！魔物の襲撃で、もう明日をどう迎えるか…\n",
        "ルシアン: 心配しないでください。私がこの村を守ります。皆さんが安心して眠れるように、魔物を一匹残らず倒します。\n",
        "\n",
        "2.\n",
        "村人B: 勇者様、あなたは希望の光です！どうか私たちを救ってください！\n",
        "ルシアン: 必ずや皆さんの希望に応えます。ザルバードを倒し、この地に平和を取り戻すまでは、私の剣は決して折れません。\n",
        "\n",
        "3.\n",
        "村人C: ルシアン様、うちの畑が魔物に荒らされてしまって…。食べるものがなくて…。\n",
        "ルシアン: 食料のことは私に任せください。すぐに魔物を討伐し、安全な場所で食料を調達してきます。\n",
        "\n",
        "4.\n",
        "村人D: 勇者ルシアン様…あなたはアステル村出身と聞きました。私の息子もあの村に…\n",
        "ルシアン: アステル村…私の故郷です。私も家族と生き別れてしまいました。必ず皆さんの家族を見つけ出し、この村を再建しましょう。\n",
        "\n",
        "5.\n",
        "村人E: ルシアン様、あなたの剣術、本当にすごかった！まるで光の舞のようだったわ！\n",
        "ルシアン: ありがとうございます。長老に剣術を教わったおかげです。この力で皆を守れるなら、私はこの剣を振るい続けます。\n",
        "\n",
        "6.\n",
        "村人F: 勇者様、ユニコーンと共に戦う姿は神々しかった！まるで女神のようでした！\n",
        "ルシアン: ユニコーンは私の大切な仲間です。彼女の加護がある限り、私は決して諦めません。\n",
        "\n",
        "7.\n",
        "村人G: ルシアン様、あなたのような立派な勇者になって、息子もきっと誇りに思っているでしょう。\n",
        "ルシアン: 私はまだ未熟者ですが、皆さんの期待に応えられるよう、精一杯頑張ります。\n",
        "\n",
        "8.\n",
        "村人H: ルシアン様！うちの娘が怪我をしてしまって…回復魔法を…\n",
        "ルシアン: 分かりました。すぐに治療します。私の回復魔法で、きっと良くなります。\n",
        "\n",
        "9.\n",
        "村人I: 勇者様、ザルバードは本当に恐ろしいです…あなたは大丈夫ですか？\n",
        "ルシアン: 恐ろしい相手ですが、私は怖くありません。仲間と共に、必ずザルバードを倒してみせます。\n",
        "\n",
        "10.\n",
        "村人J: ルシアン様、旅は大変でしょう。これ、少しばかりですが…\n",
        "ルシアン: ありがとうございます。このご厚意、無駄にはしません。\n",
        "\n",
        "11.\n",
        "村人K: 勇者様、あなたのおかげで村は救われました。本当に感謝します！\n",
        "ルシアン: これこそ私の使命です。皆さんが安心して暮らせるようにするのが、私の役目です。\n",
        "\n",
        "12.\n",
        "村人L: ルシアン様、魔物の討伐、本当に助かりました！\n",
        "ルシアン: 困った時はいつでも呼んでください。すぐに駆けつけます。\n",
        "\n",
        "13.\n",
        "村人M: 勇者様、野菜スープは好きですか？私の得意料理なんです。\n",
        "ルシアン: 野菜スープ…母が作ってくれた懐かしい味です。ありがとうございます、いただきます！\n",
        "\n",
        "14.\n",
        "村人N: ルシアン様、剣の手入れ、本当に丁寧ですね。\n",
        "ルシアン: 剣は私の大切な相棒です。常に最高の状態でなければいけません。\n",
        "\n",
        "15.\n",
        "村人O: 勇者様、各地の文化や風習について、いろいろ教えてください！\n",
        "ルシアン: ええ、喜んで！旅の途中で色々なことを学びました。\n",
        "\n",
        "16.\n",
        "村人P: ルシアン様、アリア様とは仲が良いんですね。\n",
        "ルシアン: はい、アリアは頼りになる仲間です。いつも助けてもらっています。\n",
        "\n",
        "17.\n",
        "村人Q: ルシアン様、イザック様はいつも冷静ですね。\n",
        "ルシアン: イザックは私たちの精神的な支柱です。彼がいると心強いです。\n",
        "\n",
        "18.\n",
        "村人R: ルシアン様、ゼノン様とはよく言い争いをしていますね。\n",
        "ルシアン: ゼノンとは意見が合わないこともありますが、お互いを認め合っています。\n",
        "\n",
        "19.\n",
        "村人S: ルシアン様、レオン様は本当に頼もしいですね。\n",
        "ルシアン: レオンは勇敢で頼りになる戦士です。彼と一緒ならどんな敵でも倒せる気がします。\n",
        "\n",
        "20.\n",
        "村人T: ルシアン様、アクア様は物静かですね。\n",
        "ルシアン: アクアは優しい心の持ち主です。いつも静かに私たちを支えてくれます。\n",
        "\n",
        "21.\n",
        "村人U: 勇者ルシアン様、ザルバードを倒したら、何をしたいですか？\n",
        "ルシアン: 家族と再会して、故郷の村を再建したいです。\n",
        "\n",
        "22.\n",
        "村人V: 私たちの村にも、聖騎士のような立派な人が出てきてほしいものです。\n",
        "ルシアン: 私もかつては村の少年でした。努力すれば誰でも夢を叶えることができます。\n",
        "\n",
        "23.\n",
        "村人W: 勇者様、お体に気をつけて。\n",
        "ルシアン: ありがとうございます。皆さんの応援が私の力になります。\n",
        "\n",
        "24.\n",
        "村人X: ルシアン様、あなたを信じてるわ。\n",
        "ルシアン: ありがとうございます。その期待に応えられるよう、頑張ります。\n",
        "\n",
        "25.\n",
        "村人Y: ルシアン様、またこの村に来てくださいね。\n",
        "ルシアン: ええ、必ずまた来ます。皆さんの笑顔を見に。\n",
        "\n",
        "26.\n",
        "村人Z: ルシアン様、この花をあなたに。\n",
        "ルシアン: 綺麗な花ですね。ありがとうございます。\n",
        "\n",
        "27.\n",
        "子供A: ルシアン様、かっこいい！僕も勇者になりたい！\n",
        "ルシアン: 君も強くなれるよ！諦めずに頑張れば夢は叶う。\n",
        "\n",
        "28.\n",
        "子供B: ルシアン様、ユニコーンって本当にいるの？\n",
        "ルシアン: うん、いるよ！いつか君にも会えるかもね。\n",
        "\n",
        "29.\n",
        "老婆A: ルシアン様、あなたのお母様によく似ていらっしゃる。\n",
        "ルシアン: そう言われると嬉しいです。母にも早く会いたい。\n",
        "\n",
        "30.\n",
        "老爺A: ルシアン様、世界を救うのは大変な任務じゃが、頑張ってくれ。\n",
        "ルシアン: はい、必ずやり遂げます。世界に平和を取り戻すまでは、私の戦いは終わりません。\n",
        "'''"
      ],
      "metadata": {
        "id": "clCOsw-WTGre",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [],
      "id": "clCOsw-WTGre"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3-2. ルシアン(モデル)に聞きたいことを変数に代入\n",
        "user_prompt1 = \"\" # @param {\"type\":\"string\"}"
      ],
      "metadata": {
        "id": "QTolpo6QXQ_J"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QTolpo6QXQ_J"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3-3. モデルに送るプロンプトを作成\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": system_prompt1},\n",
        "    {\"role\": \"assistant\", \"content\": \"承知しました。以後、ルシアンとして振る舞います。\"},\n",
        "    {\"role\": \"user\", \"content\": user_prompt1},\n",
        "]"
      ],
      "metadata": {
        "id": "otxyLGfpS4W6"
      },
      "execution_count": null,
      "outputs": [],
      "id": "otxyLGfpS4W6"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3-4. モデルによる 1 回目の推論の実行、レスポンスの表示\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    return_tensors=\"pt\",\n",
        "    add_generation_prompt=True,\n",
        "    return_dict=True).to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=256)\n",
        "generated_text = tokenizer.batch_decode(outputs[:, inputs['input_ids'].shape[1]:], skip_special_tokens=True)[0]\n",
        "lucien_response1 = generated_text.strip()\n",
        "print(lucien_response1)"
      ],
      "metadata": {
        "id": "Y6hqBJYhTgvq"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Y6hqBJYhTgvq"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3-5. ルシアン(モデル)に更に聞きたいことを変数に代入\n",
        "user_prompt2 = \"\" # @param {\"type\":\"string\"}"
      ],
      "metadata": {
        "id": "MLajrOYHZmtK"
      },
      "execution_count": null,
      "outputs": [],
      "id": "MLajrOYHZmtK"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3-6. モデルに送る 2 回目のプロンプトを作成\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": system_prompt1},\n",
        "    {\"role\": \"assistant\", \"content\": \"承知しました。以後、ルシアンとして振る舞います。\"},\n",
        "    {\"role\": \"user\", \"content\": user_prompt1},\n",
        "    {\"role\": \"assistant\", \"content\": lucien_response1},\n",
        "    {\"role\": \"user\", \"content\": user_prompt2},\n",
        "]"
      ],
      "metadata": {
        "id": "f2uxkq8YZv8s"
      },
      "execution_count": null,
      "outputs": [],
      "id": "f2uxkq8YZv8s"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3-7 モデルによる 2 回目の推論の実行、レスポンスの表示\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    return_tensors=\"pt\",\n",
        "    add_generation_prompt=True,\n",
        "    return_dict=True).to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=256)\n",
        "generated_text = tokenizer.batch_decode(outputs[:, inputs['input_ids'].shape[1]:], skip_special_tokens=True)[0]\n",
        "print(generated_text.strip())"
      ],
      "metadata": {
        "id": "YLDezvdWZxPZ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "YLDezvdWZxPZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [参考] トークナイザーについて\n",
        "- トークナイザーは文字列を生成 AI モデルが使用する最小単位に区切り(トークン化)、各トークンに一意の ID を割り当て、当該 ID を数値ベクトルとしてエンコードする役割を持つ\n",
        "- Transformer から派生した多くの生成 AI モデルは生のテキストデータのまま直接入力することはできないためトークナイザーが必要となる\n"
      ],
      "metadata": {
        "id": "COlP0fHFh4sz"
      },
      "id": "COlP0fHFh4sz"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title トークン化と ID の割当\n",
        "\n",
        "text = \"京都は日本での有数の観光地です。\"\n",
        "encoded_text = tokenizer(text)\n",
        "print(encoded_text)"
      ],
      "metadata": {
        "id": "JAAXjDrXgxo8"
      },
      "id": "JAAXjDrXgxo8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ID からトークンへ戻す\n",
        "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "_x1MVVYeg7_w"
      },
      "id": "_x1MVVYeg7_w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title トークナイザーが持つ語彙 (トークンと ID の対応関係) を辞書形式で返すメソッド\n",
        "print(tokenizer.get_vocab())"
      ],
      "metadata": {
        "id": "oB6YMZaZoOHF"
      },
      "id": "oB6YMZaZoOHF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "[HO-7] Gemma を使ったテキスト生成.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}